algo:
  name: dqn

model:
  name: dqn

load_checkpoint: false
load_path: path

network:
  name: dqn
  dueling: True
  atoms: 1
  noisy: True
  cnn:
    activation: relu
    initializer:
      name: variance_scaling_initializer
      scale: 2

    convs:    
      - filters: 32
        kernel_size: 8
        strides: 4
        padding: 'VALID'
      - filters: 64
        kernel_size: 4
        strides: 2
        padding: 'VALID'
      - filters: 64
        kernel_size: 3
        strides: 1
        padding: 'VALID'
    
    
  units: [256]
  activation: relu
  initializer:
    name: variance_scaling_initializer
    scale: 2

config:
  REWARD_SCALE: 1
  REWARD_SHIFT: 0
  GAMMA : 0.99
  LEARNING_RATE : 0.0004
  STEPS_PER_EPOCH : 4
  BATCH_SIZE : 128
  EPSILON : 0 #.90
  MIN_EPSILON : 0 #.02
  EPSILON_DECAY_FRAMES : 100000
  NUM_EPOCHS_TO_COPY : 10000
  NAME : 'pong_dddqn_config1'
  ENV_NAME:  PongNoFrameskip-v4
  IS_DOUBLE : True
  SCORE_TO_WIN : 20.9
  NUM_STEPS_FILL_BUFFER : 10000
  REPLAY_BUFFER_TYPE : 'normal'
  REPLAY_BUFFER_SIZE : 100000
  PRIORITY_BETA : 0.4
  PRIORITY_ALPHA : 0.6
  BETA_DECAY_FRAMES : 100000
  MAX_BETA : 1
  STEPS_NUM : 3
  EPISODES_TO_LOG : 10
  LIVES_REWARD : 1
  ATOMS_NUM : 1
