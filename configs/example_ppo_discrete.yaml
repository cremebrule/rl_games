algo:
  name: a2c_discrete

model:
  name: discrete_a2c

load_checkpoint: false
load_path: path

network:
  name: actor_critic
  separate: false
  space: 
    discrete:

  cnn:
    activation: relu
    initializer:
      name: orthogonal_initializer
      gain: 1.41421356237

    convs:    
      - filters: 32
        kernel_size: 8
        strides: 4
        padding: 'VALID'
      - filters: 64
        kernel_size: 4
        strides: 2
        padding: 'VALID'
      - filters: 64
        kernel_size: 3
        strides: 1
        padding: 'VALID'
    
    
  units: [512]
  activation: relu
  initializer:
    name: orthogonal_initializer
    gain: 1.41421356237

config:
  REWARD_SCALE: 1
  REWARD_SHIFT: 0
  NORMALIZE_ADVANTAGE: True
  GAMMA: 0.99
  TAU: 0.9
  LEARNING_RATE: 5e-4
  NAME: atari
  SCORE_TO_WIN: 20.9
  GRAD_NORM: 0.5
  ENTROPY_COEF: 0.004
  TRUNCATE_GRADS: True
  ENV_NAME:  PongNoFrameskip-v4
  PPO: true
  E_CLIP: 0.1
  CLIP_VALUE: True
  NUM_ACTORS: 16
  STEPS_NUM: 16
  MINIBATCH_SIZE: 64
  MINI_EPOCHS: 8
  CRITIC_COEF: 1
  LR_SCHEDULE:  NONE
  LR_THRESHOLD: 0.008
  NORMALIZE_INPUT: False
  SEQ_LEN: 8