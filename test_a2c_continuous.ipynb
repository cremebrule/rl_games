{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "import roboschool\n",
    "sess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trrrrr/anaconda3/envs/rl/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import wrappers\n",
    "\n",
    "env_name ='RoboschoolAnt-v1' #'LunarLanderContinuous-v2'#'BipedalWalker-v2'#'LunarLander-v2' #'MountainCarContinuous-v0'#'CarRacing-v0'#'CartPole-v1' #'RoboschoolAnt-v1' #'CarRacing-v0' #'LunarLander-v2' #'Acrobot-v1' #\n",
    "env = gym.make(env_name)\n",
    "print(env.action_space.low)\n",
    "print(env.action_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-12 09:01:53,804\tINFO node.py:469 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-12_09-01-53_13520/logs.\n",
      "2019-05-12 09:01:53,915\tINFO services.py:407 -- Waiting for redis server at 127.0.0.1:50348 to respond...\n",
      "2019-05-12 09:01:54,037\tINFO services.py:407 -- Waiting for redis server at 127.0.0.1:40934 to respond...\n",
      "2019-05-12 09:01:54,044\tINFO services.py:804 -- Starting Redis shard with 0.1 GB max memory.\n",
      "2019-05-12 09:01:54,102\tINFO node.py:483 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-05-12_09-01-53_13520/logs.\n",
      "2019-05-12 09:01:54,104\tINFO services.py:1427 -- Starting the Plasma object store with 0.1 GB memory using /dev/shm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.3.104',\n",
       " 'redis_address': '192.168.3.104:50348',\n",
       " 'object_store_address': '/tmp/ray/session_2019-05-12_09-01-53_13520/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-05-12_09-01-53_13520/sockets/raylet',\n",
       " 'webui_url': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(redis_max_memory=1024*1024*100, object_store_memory=1024*1024*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/trrrrr/Documents/github/ml/dqn_atari/networks.py:232: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/trrrrr/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-12 09:01:58,319\tERROR worker.py:1672 -- WARNING: 24 workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/trrrrr/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from a2c_v2 import A2CAgent\n",
    "import tr_helpers\n",
    "import networks\n",
    "\n",
    "a2c_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'TAU' : 0.9,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'NAME' : 'Supermario',\n",
    "    'SCORE_TO_WIN' : 5000,\n",
    "    'EPISODES_TO_LOG' : 20, \n",
    "    'LIVES_REWARD' : 5,\n",
    "    'GRAD_NORM' : 0.5,\n",
    "    'ENTROPY_COEF' : 0.000,\n",
    "    'TRUNCATE_GRADS' : True,\n",
    "    'ENV_NAME' : env_name,\n",
    "    'PPO' : True,\n",
    "    'E_CLIP' : 0.2,\n",
    "    'NUM_ACTORS' : 16,\n",
    "    'STEPS_NUM' : 128,\n",
    "    'MINIBATCH_SIZE' : 512,\n",
    "    'MINI_EPOCHS' : 4,\n",
    "    'CRITIC_COEF' : 1,\n",
    "}\n",
    "#self, sess, env_name, observation_shape, actions_num, config = default_config\n",
    "observation_shape = env.observation_space.shape\n",
    "action_space = env.action_space\n",
    "\n",
    "agent = A2CAgent(sess,'mario', env.observation_space, False, action_space, a2c_config)\n",
    "#agent.restore('nn/a2cBipedalWalker-v2')\n",
    "#agent.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/trrrrr/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from nn/a2cRoboschoolAnt-v1\n",
      "reset\n",
      "reward: 10112.89573068732\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "agent.restore('nn/a2cRoboschoolAnt-v1')\n",
    "\n",
    "def evaluate(env,t_max=5000):\n",
    "    rewards = []\n",
    "    env._max_episode_steps = 5000\n",
    "    env.batch_mode = False\n",
    "    print('reset')\n",
    "    #env = env.old_env\n",
    "    s = env.reset()\n",
    "    reward = 0\n",
    "    for it in range(t_max):\n",
    "        action = agent.get_action([s], False)\n",
    "        \n",
    "        #ad = agent.get_action_distribution([s])\n",
    "        #print(ad)\n",
    "        s, r, done, _ = env.step(np.squeeze(action, axis = 0))\n",
    "        #print(action)\n",
    "        env.render()\n",
    "        reward += r\n",
    "        \n",
    "            \n",
    "        if done:\n",
    "            break       \n",
    "        \n",
    "    return reward\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "#env_monitor = wrappers.make_atari_deepmind(env_name, noop_max=30, skip=4)\n",
    "#env_monitor = wrappers.ReallyDoneWrapper(env_monitor)\n",
    "#env_monitor = gym.wrappers.Monitor(env,directory='video_ppo',force=True)\n",
    "\n",
    "sessions = [print('reward:', evaluate(env)) for _ in range(1)]\n",
    "#env_monitor.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "obs, r, done, _ = env.step(2)\n",
    "\n",
    "done = False\n",
    "for _ in range(130):\n",
    "    obs, _, done, _ = env.step(1)\n",
    "    #env.render()\n",
    "    obs = np.array(obs)\n",
    "    if done:\n",
    "        print('done')\n",
    "        break\n",
    "plt.title(\"what your network gonna see\")\n",
    "print (obs.shape)\n",
    "plt.imshow(obs[:,:,0],interpolation='none',cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "gym.envs.registry.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
