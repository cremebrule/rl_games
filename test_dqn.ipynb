{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "sess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.8)\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trrrrr/anaconda3/envs/rl/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
      "(84, 84, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wrappers import make_atari_deepmind\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "env_name = \"PongNoFrameskip-v4\"\n",
    "#env_name = \"BreakoutNoFrameskip-v4\"\n",
    "#env_name = \"SpaceInvadersNoFrameskip-v4\"\n",
    "env = make_atari_deepmind(env_name, skip=4)\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "print(n_actions)\n",
    "print(env.unwrapped.get_action_meanings())\n",
    "\n",
    "obs = env.reset()\n",
    "obs, r, done, _ = env.step(2)\n",
    "\n",
    "done = False\n",
    "for _ in range(130):\n",
    "    obs, _, done, _ = env.step(1)\n",
    "    #env.render()\n",
    "    obs = np.array(obs)\n",
    "    if done:\n",
    "        print('done')\n",
    "        break\n",
    "plt.title(\"what your network gonna see\")\n",
    "print (obs.shape)\n",
    "plt.imshow(obs[:,:,0],interpolation='none',cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dqnagent import DQNAgent\n",
    "import tr_helpers\n",
    "import networks\n",
    "\n",
    "\n",
    "#agent.epsilon = 0.5\n",
    "\n",
    "breakout_dddqn_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 8,\n",
    "    'BATCH_SIZE' : 32 * 2,\n",
    "    'EPSILON' : 0,\n",
    "    'MIN_EPSILON' : 0,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'ENDDDQN2',\n",
    "    'IS_DOUBLE' : False,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 420,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 1000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'STEPS_NUM' : 3,\n",
    "    'NETWORK' : networks.AtariNoisyDuelingDQN(),\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 20, \n",
    "    'LIVES_REWARD' : 5,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "\n",
    "spaceinviders_dddqn_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 8,\n",
    "    'BATCH_SIZE' : 32 * 2,\n",
    "    'EPSILON' : 0,\n",
    "    'MIN_EPSILON' : 0,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'ENDDDQN2',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 5000,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'STEPS_NUM' : 1,\n",
    "    'NETWORK' : networks.AtariNoisyDuelingDQN(),\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),#tr_helpers.DefaultRewardsShaper(clip_value=3, scale_value = 0.05),\n",
    "    'EPISODES_TO_LOG' : 15, \n",
    "    'LIVES_REWARD' : 3,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "\n",
    "pong_dddqn_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'PongDDDQN',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 20,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDuelingDQN(),\n",
    "    'STEPS_NUM' : 1,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "\n",
    "pong_dddqn_config7 = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : 0,\n",
    "    'MIN_EPSILON' : 0,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'pong_dddqn_config6',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 18,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariNoisyDuelingDQN(),\n",
    "    'STEPS_NUM' : 3,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "pong_dddqn_config0 = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'pong_dddqn_config0',\n",
    "    'IS_DOUBLE' : False,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 18,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'prioritized',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDQN(),\n",
    "    'STEPS_NUM' : 1,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "\n",
    "pong_dddqn_config1 = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'pong_dddqn_config1',\n",
    "    'IS_DOUBLE' : False,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 18,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDQN(),\n",
    "    'STEPS_NUM' : 1,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "pong_dddqn_config3 = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'pong_dddqn_config3',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 18,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDuelingDQN(),\n",
    "    'STEPS_NUM' : 1,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "agent = DQNAgent(env, sess, env_name, config = pong_dddqn_config0)\n",
    "#agent.restore('nn/pong_dddqn_config0PongNoFrameskip-v4')\n",
    "#agent.epsilon = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per seconds:  40.66934563916247\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-775f89c97f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/github/ml/dqn_atari/dqnagent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_prioritized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_prioritized_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtd_loss_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_errors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_priorities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.save(\"./nn/ENDDDQN2\" + env_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrappers\n",
    "#print(env.unwrapped.get_action_meanings())\n",
    "def evaluate(env,t_max=10000):\n",
    "    rewards = []\n",
    "    env._max_episode_steps = 9999\n",
    "    print('reset')\n",
    "    #env = env.old_env\n",
    "    s = env.reset()\n",
    "    reward = 0\n",
    "    for it in range(t_max):\n",
    "        #nv.render()\n",
    "        #e.render()\n",
    "        qvalues = agent.get_qvalues([s])\n",
    "        action = np.argmax(qvalues)\n",
    "        s, r, done, _ = env.step(action)\n",
    "        reward += r\n",
    "        \n",
    "            \n",
    "        if done:\n",
    "            break       \n",
    "        \n",
    "    return reward\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "env_monitor = wrappers.make_atari_deepmind(env_name, noop_max=30, skip=4)\n",
    "#env_monitor = wrappers.ReallyDoneWrapper(env_monitor)\n",
    "env_monitor = gym.wrappers.Monitor(env_monitor,directory='video_dddqn05',force=True)\n",
    "\n",
    "sessions = [print('reward:', evaluate(env_monitor)) for _ in range(1)]\n",
    "env_monitor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#agent = DQNAgent(env, sess, ExperienceBuffer(EXP_BUFFER_CAPACITY), env_name, config = dqn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.reset()\n",
    "#agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
