{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "sess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.8)\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import envs\n",
    "#print(envs.registry.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "done\n",
      "(84, 84, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wrappers import make_atari_deepmind\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#env_name = \"PongNoFrameskip-v4\"\n",
    "env_name = \"BreakoutNoFrameskip-v4\"\n",
    "env = make_atari_deepmind(env_name)\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "print(n_actions)\n",
    "obs = env.reset()\n",
    "obs, r, done, _ = env.step(2)\n",
    "#print(obs.shape)\n",
    "#print(is_done)\n",
    "done = False\n",
    "for _ in range(2000):\n",
    "    obs, _, done, _ = env.step(3)\n",
    "    obs = np.array(obs)\n",
    "    if done:\n",
    "        print('done')\n",
    "        break\n",
    "plt.title(\"what your network gonna see\")\n",
    "print (obs.shape)\n",
    "plt.imshow(obs[:,:,0],interpolation='none',cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dqnagent import DQNAgent\n",
    "\n",
    "import networks\n",
    "\n",
    "\n",
    "#agent.epsilon = 0.5\n",
    "\n",
    "breakout_dddqn_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 8,\n",
    "    'BATCH_SIZE' : 32 * 2,\n",
    "    'EPSILON' : 0,\n",
    "    'MIN_EPSILON' : 0,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'ENDDDQN2',\n",
    "    'IS_DOUBLE' : False,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 420,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 1000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'CLIP_REWARDS' : True, # I don't clip rewards in wrappers because I want to see right values in tensorboard \n",
    "    'LIVES_REWARD' : 5, # 5 for breakout, just divider\n",
    "    'STEPS_NUM' : 2,\n",
    "    'NETWORK' : networks.AtariNoisyDuelingDQN()\n",
    "    }\n",
    "\n",
    "\n",
    "pong_dddqn_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'PongDDDQN',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 20,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'CLIP_REWARDS' : True,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDuelingDQN(),\n",
    "    'LIVES_REWARD' : 1,\n",
    "    'STEPS_NUM' : 1\n",
    "    }\n",
    "agent = DQNAgent(env, sess, env_name, config = breakout_dddqn_config)\n",
    "#agent.restore('nn/NDDDQNBreakoutNoFrameskip-v4')\n",
    "#agent.epsilon = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "saving next best rewards:  2.75\n",
      "Frames per seconds:  201.74358469191745\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Frames per seconds:  203.67093901133617\n",
      "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "saving next best rewards:  3.5\n",
      "[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0]\n",
      "Frames per seconds:  203.62895454063056\n",
      "[1.0, 1.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Frames per seconds:  203.50606708828283\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "Frames per seconds:  202.31434891794993\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Frames per seconds:  195.89946835411348\n",
      "[0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
      "[1.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "Frames per seconds:  200.2524602315933\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.epsilon = 0.2\n",
    "#agent.train()\n",
    "import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_monitor.close()\n",
    "print(env.unwrapped.get_action_meanings())\n",
    "def evaluate(env,t_max=10000):\n",
    "    rewards = []\n",
    "    env._max_episode_steps = 9999\n",
    "    print('reset')\n",
    "    #env = env.old_env\n",
    "    s = env.reset()\n",
    "    reward = 0\n",
    "    for it in range(t_max):\n",
    "        #e.render()\n",
    "        qvalues = agent.get_qvalues([s])\n",
    "        action = np.argmax(qvalues)\n",
    "        s, r, done, _ = env.step(action)\n",
    "        reward += r\n",
    "        \n",
    "            \n",
    "        if done:\n",
    "            \n",
    "            break       \n",
    "        \n",
    "    return reward\n",
    "\n",
    "import gym.wrappers\n",
    "env_monitor = wrappers.make_atari_deepmind(env_name)\n",
    "env_monitor = wrappers.ReallyDoneWrapper(env_monitor)\n",
    "env_monitor = gym.wrappers.Monitor(env_monitor,directory='video_dddqn01',force=True, write_upon_reset=True)\n",
    "sessions = [print('reward:', evaluate(env_monitor)) for _ in range(1)]\n",
    "env_monitor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#agent = DQNAgent(env, sess, ExperienceBuffer(EXP_BUFFER_CAPACITY), env_name, config = dqn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.reset()\n",
    "#agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "class ExperienceBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=True)\n",
    "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), \\\n",
    "               np.array(dones, dtype=np.uint8), np.array(next_states)\n",
    "\n",
    "from experience import ReplayBuffer\n",
    "import wrappers\n",
    "import gym\n",
    "import time\n",
    "env = None\n",
    "def play_step(buf, env, curr_state):\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # do step in the environment\n",
    "    #qvalues = agent.get_qvalues([curr_state])\n",
    "    #action = np.argmax(qvalues)\n",
    "    new_state, reward, is_done, _ = env.step(action)\n",
    "    curr_state = new_state\n",
    "    #buf.add(curr_state, action, reward, is_done, new_state)\n",
    "    #obs_batch, act_batch, reward_batch, next_obs_batch, is_done_batch  = buf.sample(32)\n",
    "    if is_done:\n",
    "        curr_state = env.reset() \n",
    "    return curr_state\n",
    "\n",
    "def do_test():\n",
    "    buf = None\n",
    "    buf = ReplayBuffer(100000)\n",
    "    frame = 0\n",
    "    dt = 0\n",
    "    env = wrappers.make_atari_deepmind(\"BreakoutNoFrameskip-v4\")\n",
    "    curr_state = env.reset() \n",
    "    while True:\n",
    "        frame += 1\n",
    "        t1 = time.time()\n",
    "        curr_state = play_step(buf, env, curr_state)\n",
    "        t2 = time.time()\n",
    "        dt += t2 - t1\n",
    "        \n",
    "        if frame % 1000 == 0 and frame != 0:\n",
    "            print(dt)\n",
    "            print(frame)\n",
    "            dt = 0\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def show_mem_usage():\n",
    "    '''Displays memory usage from inspection\n",
    "    of global variables in this notebook'''\n",
    "    gl = sys._getframe(1).f_globals\n",
    "    vars= {}\n",
    "    for k,v in list(gl.items()):\n",
    "        # for pandas dataframes\n",
    "        if hasattr(v, 'memory_usage'):\n",
    "            mem = v.memory_usage(deep=True)\n",
    "            if not np.isscalar(mem):\n",
    "                mem = mem.sum()\n",
    "            vars.setdefault(id(v),[mem]).append(k)\n",
    "        # work around for a bug\n",
    "        elif isinstance(v,pd.Panel):\n",
    "            v = v.values\n",
    "        vars.setdefault(id(v),[sys.getsizeof(v)]).append(k)\n",
    "    total = 0\n",
    "    for k,(value,*names) in vars.items():\n",
    "        if value>1e6:\n",
    "            print(names,\"%.3fMB\"%(value/1e6))\n",
    "        total += value\n",
    "    print(\"%.3fMB\"%(total/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "s  = deque([], maxlen=2)\n",
    "s.append(1)\n",
    "s.append(2)\n",
    "print(s)\n",
    "print(s[-1])\n",
    "s.append(3)\n",
    "s.clear()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
