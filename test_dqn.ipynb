{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "sess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "gpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.8)\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trrrrr/anaconda3/envs/rl/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
      "(84, 84, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wrappers import make_atari_deepmind\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "env_name = \"PongNoFrameskip-v4\"\n",
    "#env_name = \"BreakoutNoFrameskip-v4\"\n",
    "#env_name = \"SpaceInvadersNoFrameskip-v4\"\n",
    "env = make_atari_deepmind(env_name, skip=4)\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "print(n_actions)\n",
    "print(env.unwrapped.get_action_meanings())\n",
    "\n",
    "obs = env.reset()\n",
    "obs, r, done, _ = env.step(2)\n",
    "#print(obs.shape)\n",
    "#print(is_done)\n",
    "done = False\n",
    "for _ in range(130):\n",
    "    obs, _, done, _ = env.step(1)\n",
    "    #env.render()\n",
    "    obs = np.array(obs)\n",
    "    if done:\n",
    "        print('done')\n",
    "        break\n",
    "plt.title(\"what your network gonna see\")\n",
    "print (obs.shape)\n",
    "plt.imshow(obs[:,:,0],interpolation='none',cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from nn/pong_dddqn_config0PongNoFrameskip-v4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dqnagent import DQNAgent\n",
    "import tr_helpers\n",
    "import networks\n",
    "\n",
    "\n",
    "#agent.epsilon = 0.5\n",
    "\n",
    "breakout_dddqn_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 8,\n",
    "    'BATCH_SIZE' : 32 * 2,\n",
    "    'EPSILON' : 0,\n",
    "    'MIN_EPSILON' : 0,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'ENDDDQN2',\n",
    "    'IS_DOUBLE' : False,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 420,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 1000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'STEPS_NUM' : 3,\n",
    "    'NETWORK' : networks.AtariNoisyDuelingDQN(),\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 20, \n",
    "    'LIVES_REWARD' : 5,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "\n",
    "spaceinviders_dddqn_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 8,\n",
    "    'BATCH_SIZE' : 32 * 2,\n",
    "    'EPSILON' : 0,\n",
    "    'MIN_EPSILON' : 0,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'ENDDDQN2',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 5000,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'STEPS_NUM' : 1,\n",
    "    'NETWORK' : networks.AtariNoisyDuelingDQN(),\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),#tr_helpers.DefaultRewardsShaper(clip_value=3, scale_value = 0.05),\n",
    "    'EPISODES_TO_LOG' : 15, \n",
    "    'LIVES_REWARD' : 3,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "\n",
    "pong_dddqn_config = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'PongDDDQN',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 20,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDuelingDQN(),\n",
    "    'STEPS_NUM' : 1,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "\n",
    "pong_dddqn_config7 = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : 0,\n",
    "    'MIN_EPSILON' : 0,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'pong_dddqn_config6',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 18,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariNoisyDuelingDQN(),\n",
    "    'STEPS_NUM' : 3,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "pong_dddqn_config0 = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'pong_dddqn_config0',\n",
    "    'IS_DOUBLE' : False,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 18,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'prioritized',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDQN(),\n",
    "    'STEPS_NUM' : 1,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "\n",
    "pong_dddqn_config1 = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'pong_dddqn_config1',\n",
    "    'IS_DOUBLE' : False,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 18,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDQN(),\n",
    "    'STEPS_NUM' : 1,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "pong_dddqn_config3 = {\n",
    "    'GAMMA' : 0.99,\n",
    "    'LEARNING_RATE' : 1e-4,\n",
    "    'STEPS_PER_EPOCH' : 4,\n",
    "    'BATCH_SIZE' : 32 * 4,\n",
    "    'EPSILON' : .90,\n",
    "    'MIN_EPSILON' : 0.02,\n",
    "    'EPSILON_DECAY_FRAMES' : 100000,\n",
    "    'NUM_EPOCHS_TO_COPY' : 1000,\n",
    "    'NAME' : 'pong_dddqn_config3',\n",
    "    'IS_DOUBLE' : True,\n",
    "    'DUELING_TYPE' : 'AVERAGE',\n",
    "    'SCORE_TO_WIN' : 18,\n",
    "    'NUM_STEPS_FILL_BUFFER' : 10000,\n",
    "    'REPLAY_BUFFER_TYPE' : 'normal',\n",
    "    'REPLAY_BUFFER_SIZE' : 100000,\n",
    "    'PRIORITY_BETA' : 0.4,\n",
    "    'PRIORITY_ALPHA' : 0.6,\n",
    "    'BETA_DECAY_FRAMES' : 1e5,\n",
    "    'MAX_BETA' : 1,\n",
    "    'NETWORK' : networks.AtariDuelingDQN(),\n",
    "    'STEPS_NUM' : 1,\n",
    "    'REWARD_SHAPER' : tr_helpers.DefaultRewardsShaper(),\n",
    "    'EPISODES_TO_LOG' : 10, \n",
    "    'LIVES_REWARD' : 1,\n",
    "    'ATOMS_NUM' : 1\n",
    "    }\n",
    "agent = DQNAgent(env, sess, env_name, config = pong_dddqn_config0)\n",
    "agent.restore('nn/pong_dddqn_config0PongNoFrameskip-v4')\n",
    "#agent.epsilon = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-775f89c97f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/github/ml/dqn_atari/dqnagent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weigths_into_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NUM_STEPS_FILL_BUFFER'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mSTEPS_PER_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STEPS_PER_EPOCH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/ml/dqn_atari/dqnagent.py\u001b[0m in \u001b[0;36mplay_steps\u001b[0;34m(self, steps, epsilon)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/ml/dqn_atari/dqnagent.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mqvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/ml/dqn_atari/dqnagent.py\u001b[0m in \u001b[0;36mget_qvalues\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_qvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.save(\"./nn/ENDDDQN2\" + env_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trrrrr/anaconda3/envs/rl/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "reward: 20.0\n"
     ]
    }
   ],
   "source": [
    "import wrappers\n",
    "#print(env.unwrapped.get_action_meanings())\n",
    "def evaluate(env,t_max=10000):\n",
    "    rewards = []\n",
    "    env._max_episode_steps = 9999\n",
    "    print('reset')\n",
    "    #env = env.old_env\n",
    "    s = env.reset()\n",
    "    reward = 0\n",
    "    for it in range(t_max):\n",
    "        #nv.render()\n",
    "        #e.render()\n",
    "        qvalues = agent.get_qvalues([s])\n",
    "        action = np.argmax(qvalues)\n",
    "        s, r, done, _ = env.step(action)\n",
    "        reward += r\n",
    "        \n",
    "            \n",
    "        if done:\n",
    "            break       \n",
    "        \n",
    "    return reward\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "env_monitor = wrappers.make_atari_deepmind(env_name, noop_max=30, skip=4)\n",
    "#env_monitor = wrappers.ReallyDoneWrapper(env_monitor)\n",
    "env_monitor = gym.wrappers.Monitor(env_monitor,directory='video_dddqn05',force=True)\n",
    "\n",
    "sessions = [print('reward:', evaluate(env_monitor)) for _ in range(1)]\n",
    "env_monitor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#agent = DQNAgent(env, sess, ExperienceBuffer(EXP_BUFFER_CAPACITY), env_name, config = dqn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.reset()\n",
    "#agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
